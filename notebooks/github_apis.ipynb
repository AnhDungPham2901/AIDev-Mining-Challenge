{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7e50d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAs in PR: ['c5db76dfe926ce82588cff74461994cb9792763f', '776c4d008911b32d36ac3a42dde29300d1d5b341']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "OWNER = \"getsentry\"\n",
    "REPO = \"sentry\"\n",
    "PR_NUMBER = 89131\n",
    "\n",
    "\n",
    "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n",
    "\n",
    "url = f\"https://api.github.com/repos/{OWNER}/{REPO}/pulls/{PR_NUMBER}/commits\"\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "commits = response.json()\n",
    "shas = [commit[\"sha\"] for commit in commits]\n",
    "print(\"SHAs in PR:\", shas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a6b81c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo ID: 873328\n",
      "Repo Name: sentry\n",
      "Repo Full Name: getsentry/sentry\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "REPO = \"getsentry/sentry\"\n",
    "PR_NUMBER = 89131\n",
    "\n",
    "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n",
    "\n",
    "url = f\"https://api.github.com/repos/{REPO}/pulls/{PR_NUMBER}\"\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "pr_data = response.json()\n",
    "repo_id = pr_data[\"base\"][\"repo\"][\"id\"]\n",
    "repo_name = pr_data[\"base\"][\"repo\"][\"name\"]\n",
    "repo_full_name = pr_data[\"base\"][\"repo\"][\"full_name\"]\n",
    "print(\"Repo ID:\", repo_id)\n",
    "print(\"Repo Name:\", repo_name)\n",
    "print(\"Repo Full Name:\", repo_full_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24de847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sha = \"2f9d54dda4f0c87c19e0bbeb9936f525d0587e16\"\n",
    "repo = \"AgentOps-AI/agentops\"\n",
    "url = f\"https://api.github.com/repos/{repo}/commits/{sha}\"\n",
    "r = requests.get(url, headers=headers)\n",
    "results = []\n",
    "if r.status_code == 200:\n",
    "    data = r.json()\n",
    "    for f in data.get(\"files\", []):\n",
    "        results.append({\n",
    "            \"sha\": sha,\n",
    "            \"filename\": f.get(\"filename\"),\n",
    "            \"status\": f.get(\"status\"),\n",
    "            \"additions\": f.get(\"additions\"),\n",
    "            \"deletions\": f.get(\"deletions\"),\n",
    "            \"changes\": f.get(\"changes\"),\n",
    "            \"patch\": f.get(\"patch\"),\n",
    "            \"message\": data.get(\"commit\", {}).get(\"message\")\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "355fc26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sha': '2f9d54dda4f0c87c19e0bbeb9936f525d0587e16',\n",
       "  'filename': '.github/workflows/compile-llms-txt.yml',\n",
       "  'status': 'added',\n",
       "  'additions': 38,\n",
       "  'deletions': 0,\n",
       "  'changes': 38,\n",
       "  'patch': '@@ -0,0 +1,38 @@\\n+name: Compile llms.txt\\n+\\n+on:\\n+  push:\\n+    branches: [ main ]\\n+    paths:\\n+      - \\'docs/**\\'\\n+      - \\'README.md\\'\\n+      - \\'CONTRIBUTING.md\\'\\n+      - \\'examples/*/README.md\\'\\n+      - \\'agentops/*/README.md\\'\\n+  workflow_dispatch:\\n+\\n+jobs:\\n+  compile-llms-txt:\\n+    runs-on: ubuntu-latest\\n+    steps:\\n+    - uses: actions/checkout@v4\\n+      with:\\n+        token: ${{ secrets.GITHUB_TOKEN }}\\n+        \\n+    - name: Set up Python\\n+      uses: actions/setup-python@v4\\n+      with:\\n+        python-version: \\'3.11\\'\\n+        \\n+    - name: Compile llms.txt\\n+      run: |\\n+        cd docs\\n+        python compile_llms_txt.py\\n+        \\n+    - name: Commit and push if changed\\n+      run: |\\n+        git config --local user.email \"action@github.com\"\\n+        git config --local user.name \"GitHub Action\"\\n+        git add llms.txt\\n+        git diff --staged --quiet || git commit -m \"Auto-update llms.txt from documentation changes\"\\n+        git push',\n",
       "  'message': 'Add llms.txt compilation system for AI model documentation\\n\\n- Create docs/compile_llms_txt.py script to compile all documentation\\n- Add GitHub Actions workflow to auto-update llms.txt on doc changes\\n- Generate initial llms.txt file with comprehensive AgentOps documentation\\n- Include all versions (v0, v1, v2) and key repository documentation\\n\\nCo-Authored-By: Pratyush Shukla <pratyush@agentops.ai>'},\n",
       " {'sha': '2f9d54dda4f0c87c19e0bbeb9936f525d0587e16',\n",
       "  'filename': 'docs/compile_llms_txt.py',\n",
       "  'status': 'added',\n",
       "  'additions': 47,\n",
       "  'deletions': 0,\n",
       "  'changes': 47,\n",
       "  'patch': '@@ -0,0 +1,47 @@\\n+import os\\n+from pathlib import Path\\n+\\n+def compile_llms_txt():\\n+    \"\"\"Compile all relevant documentation into llms.txt for AI model consumption.\"\"\"\\n+    current_dir = Path(os.getcwd())\\n+    content = \\'\\'\\n+    \\n+    # Define names of directories and files to exclude\\n+    excluded_names = {\\'node_modules\\', \\'.git\\', \\'__pycache__\\', \\'.venv\\', \\'images\\', \\'.pytest_cache\\', \\'dist\\', \\'build\\'}\\n+    \\n+    def should_include_file(file_path):\\n+        \"\"\"Check if a file should be included based on patterns and exclusions.\"\"\"\\n+        path_parts = Path(file_path).parts\\n+        \\n+        if any(part in excluded_names for part in path_parts):\\n+            return False\\n+            \\n+        if file_path.endswith((\\'.md\\', \\'.mdx\\')):\\n+            return True\\n+            \\n+        return False\\n+    \\n+    for root, dirs, files in os.walk(\\'..\\'):\\n+        dirs[:] = [d for d in dirs if d not in excluded_names]\\n+        \\n+        for file in files:\\n+            if should_include_file(file):\\n+                file_path = os.path.join(root, file)\\n+                relative_path = os.path.relpath(file_path, \\'..\\')\\n+                \\n+                try:\\n+                    with open(file_path, \\'r\\', encoding=\\'utf-8\\') as f:\\n+                        file_content = f.read()\\n+                    content += f\"## {relative_path}\\\\n\\\\n{file_content}\\\\n\\\\n\"\\n+                except (UnicodeDecodeError, PermissionError) as e:\\n+                    print(f\"Warning: Could not read {relative_path}: {e}\")\\n+                    continue\\n+\\n+    # Write the complete content to llms.txt in the repository root\\n+    output_path = Path(\\'../llms.txt\\')\\n+    output_path.write_text(content, encoding=\\'utf-8\\')\\n+    print(f\"Successfully compiled documentation to {output_path.absolute()}\")\\n+    print(f\"Total content length: {len(content)} characters\")\\n+\\n+if __name__ == \"__main__\":\\n+    compile_llms_txt()',\n",
       "  'message': 'Add llms.txt compilation system for AI model documentation\\n\\n- Create docs/compile_llms_txt.py script to compile all documentation\\n- Add GitHub Actions workflow to auto-update llms.txt on doc changes\\n- Generate initial llms.txt file with comprehensive AgentOps documentation\\n- Include all versions (v0, v1, v2) and key repository documentation\\n\\nCo-Authored-By: Pratyush Shukla <pratyush@agentops.ai>'},\n",
       " {'sha': '2f9d54dda4f0c87c19e0bbeb9936f525d0587e16',\n",
       "  'filename': 'llms.txt',\n",
       "  'status': 'added',\n",
       "  'additions': 22923,\n",
       "  'deletions': 0,\n",
       "  'changes': 22923,\n",
       "  'patch': None,\n",
       "  'message': 'Add llms.txt compilation system for AI model documentation\\n\\n- Create docs/compile_llms_txt.py script to compile all documentation\\n- Add GitHub Actions workflow to auto-update llms.txt on doc changes\\n- Generate initial llms.txt file with comprehensive AgentOps documentation\\n- Include all versions (v0, v1, v2) and key repository documentation\\n\\nCo-Authored-By: Pratyush Shukla <pratyush@agentops.ai>'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "814dd7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resources': {'core': {'limit': 5000, 'used': 0, 'remaining': 5000, 'reset': 1762139799}, 'search': {'limit': 30, 'used': 0, 'remaining': 30, 'reset': 1762136259}, 'graphql': {'limit': 5000, 'used': 0, 'remaining': 5000, 'reset': 1762139799}, 'integration_manifest': {'limit': 5000, 'used': 0, 'remaining': 5000, 'reset': 1762139799}, 'source_import': {'limit': 100, 'used': 0, 'remaining': 100, 'reset': 1762136259}, 'code_scanning_upload': {'limit': 5000, 'used': 0, 'remaining': 5000, 'reset': 1762139799}, 'code_scanning_autofix': {'limit': 10, 'used': 0, 'remaining': 10, 'reset': 1762136259}, 'actions_runner_registration': {'limit': 10000, 'used': 0, 'remaining': 10000, 'reset': 1762139799}, 'scim': {'limit': 15000, 'used': 0, 'remaining': 15000, 'reset': 1762139799}, 'dependency_snapshots': {'limit': 100, 'used': 0, 'remaining': 100, 'reset': 1762136259}, 'dependency_sbom': {'limit': 100, 'used': 0, 'remaining': 100, 'reset': 1762136259}, 'audit_log': {'limit': 1750, 'used': 0, 'remaining': 1750, 'reset': 1762139799}, 'audit_log_streaming': {'limit': 15, 'used': 0, 'remaining': 15, 'reset': 1762139799}, 'code_search': {'limit': 10, 'used': 0, 'remaining': 10, 'reset': 1762136259}}, 'rate': {'limit': 5000, 'used': 0, 'remaining': 5000, 'reset': 1762139799}}\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "import requests\n",
    "\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "r = requests.get(\"https://api.github.com/rate_limit\", headers={\n",
    "    \"Authorization\": f\"token {token}\"\n",
    "})\n",
    "print(r.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac51db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
